{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "0abe5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "7cc87538",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOCATION=\"./dataset/expandedDataSet.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "e2e77669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "d278fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a2372",
   "metadata": {},
   "source": [
    "<h1><b>DESCRIZIONE DEGLI ATTRIBUTI</b></h1>\n",
    "<ul>\n",
    "    <li><b>Gender:</b> Gender of the student (male/female)</li>\n",
    "    <li><b>EthnicGroup:</b> Ethnic group of the student (group A to E)</li>\n",
    "    <li><b>ParentEduc:</b> Parent(s) education background (from some_highschool to master's degree)</li>\n",
    "    <li><b>LunchType:</b> School lunch type (standard or free/reduced)</li>\n",
    "    <li><b>TestPrep:</b> Test preparation course followed (completed or none)</li>\n",
    "    <li><b>ParentMaritalStatus:</b> Parent(s) marital status (married/single/widowed/divorced)</li>\n",
    "    <li><b>PracticeSport:</b> How often the student parctice sport (never/sometimes/regularly))</li>\n",
    "    <li><b>IsFirstChild:</b> If the child is first child in the family or not (yes/no)</li>\n",
    "    <li><b>NrSiblings:</b> Number of siblings the student has (0 to 7)</li>\n",
    "    <li><b>TransportMeans:</b> Means of transport to school (schoolbus/private)</li>\n",
    "    <li><b>WklyStudyHours:</b> Weekly self-study hours(less that 5hrs; between 5 and 10hrs; more than 10hrs)</li>\n",
    "    <li><b>MathScore:</b> math test score(0-100)</li>\n",
    "    <li><b>ReadingScore:</b> reading test score(0-100)</li>\n",
    "    <li><b>WritingScore:</b> writing test score(0-100)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "0f9ee29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimino la colonna TestPrep perchè ha troppi dati mancanti\n",
    "ds.drop(\"TestPrep\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "edf07065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimino la colonna indice perchè non è significativa\n",
    "ds.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "dfc6bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimino la colonna LunchType perchè non sono sicuro che sia significativa\n",
    "ds.drop(\"LunchType\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "4a1baa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "7a759e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "6edb4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "7047392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminiamo le osservazioni che presentano dati mancanti\n",
    "ds.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "90e72b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "e1b999c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifichiamo se ci sono delle righe duplicate\n",
    "ds.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "afdb8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "6554b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mappiamo Gender su un vettore di variabili dummy\n",
    "ds.Gender.replace({'male':1,'female':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "fbca3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "3a6633ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_= pd.get_dummies(ds['EthnicGroup'], prefix='EG')\n",
    "ds = ds.join(ds_).drop('EthnicGroup',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "c29d7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "d916b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_= pd.get_dummies(ds['ParentEduc'], prefix='ParEduc')\n",
    "ds = ds.join(ds_).drop('ParentEduc',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "48591ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "812e7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_= pd.get_dummies(ds['ParentMaritalStatus'], prefix='ParMarStat')\n",
    "ds = ds.join(ds_).drop('ParentMaritalStatus',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "3d83ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "0f577cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_= pd.get_dummies(ds['PracticeSport'], prefix='sport')\n",
    "ds = ds.join(ds_).drop('PracticeSport',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "f975f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "57518784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.IsFirstChild.replace({'yes':1,'no':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "6bf74a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.TransportMeans.replace({'school_bus':1,'private':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "46aa5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_= pd.get_dummies(ds['WklyStudyHours'], prefix='studyHours')\n",
    "ds = ds.join(ds_).drop('WklyStudyHours',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "5a0c1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1ed707a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisi della correlazione (Da fare)\n",
    "ds.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "642fb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_copy = ds.copy() # questa riga serve per avere il dataset per provare la standardizzazione di sklearn ( alla fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "f268d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import*\n",
    "#Introduciamo la standardizzazione automatica di scikit learn\n",
    "lista = ds.columns.values.tolist()\n",
    "diz = {}\n",
    "for i in range(len(lista)):\n",
    "    diz[i] = lista[i]\n",
    "scaler = preprocessing.StandardScaler().fit(ds)\n",
    "X_scaled = scaler.transform(ds)\n",
    "#Viene mantenuto l'ordine delle colonne quando si standardizza, quindi andiamo a sostituire gli indici con i nomi\n",
    "#delle colonne del Dataset, questo ci servirà per suddividere il Dataset in Train e Test -set\n",
    "dsn = pd.DataFrame(X_scaled)\n",
    "dsn.rename(diz, axis='columns', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "3c6a41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suddividiamo il Dataset standardizzato in Train e Test set\n",
    "X = dsn.drop('MathScore',axis=1)\n",
    "Y = dsn['MathScore']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "b7c8e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "3977069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiamo la funzione compute_performance così da poter poi stampare\n",
    "#la tabella con le varie perfomance dei diversi modelli\n",
    "#from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "import time\n",
    "\n",
    "pd.options.display.float_format = '{:.8f}'.format\n",
    "\n",
    "def compute_performance(modelli,names,X,y):\n",
    "    score_dict = {}\n",
    "    score_dict['Modello'] = {}\n",
    "    score_dict['mse'] = {}\n",
    "    score_dict['variance'] = {}\n",
    "    score_dict['mae'] = {}\n",
    "    score_dict['mape'] = {}\n",
    "    score_dict['median_ae'] = {}\n",
    "    score_dict['r2'] = {}\n",
    "    score_dict['adjusted_r2'] = {}\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(modelli)):\n",
    "        value_predictions = modelli[i].predict(X)\n",
    "        mse = mean_squared_error(y, value_predictions)\n",
    "        variance = explained_variance_score(y,value_predictions)\n",
    "        mae = mean_absolute_error(y,value_predictions)\n",
    "        mape = mean_absolute_percentage_error(y, value_predictions)\n",
    "        median_ae = median_absolute_error(y, value_predictions)\n",
    "        r2 = r2_score(y, value_predictions)\n",
    "        adjusted_r2 = 1 - ( 1-r2 ) * ( len(value_predictions) - 1 ) / ( len(value_predictions) - X.shape[1] - 1 )\n",
    "\n",
    "        name = names[i]\n",
    "\n",
    "        score_dict['Modello'][i] = name\n",
    "        score_dict['mse'][i] = mse\n",
    "        score_dict['variance'][i] = variance\n",
    "        score_dict['mae'][i] = mae\n",
    "        score_dict['mape'][i] = mape\n",
    "        score_dict['median_ae'][i] = median_ae\n",
    "        score_dict['r2'][i] = r2\n",
    "        score_dict['adjusted_r2'][i] = adjusted_r2\n",
    "        \n",
    "        \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "437a2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "regressori = []\n",
    "nomi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14539f1",
   "metadata": {},
   "source": [
    "<h1> Modelli SVM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "98a996ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli_svm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "bfce7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#svr_reg = SVR()\n",
    "#svr_reg.fit(X_train,y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/svr_reg.sav'\n",
    "#pickle.dump(svr_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/svr_reg.sav'\n",
    "svr_reg = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "ba317f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(svr_reg)\n",
    "nomi.append(\"SVR Regressor\")\n",
    "modelli_svm.append(\"SVR Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701e7b1",
   "metadata": {},
   "source": [
    "<h1>Modelli Lineari</h1></n>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "46f975b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli_lineari = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86a3f8",
   "metadata": {},
   "source": [
    "<h2>Linear Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "ffab45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#lin_reg = LinearRegression()\n",
    "#lin_reg = lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/lin_reg.sav'\n",
    "#pickle.dump(lin_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/lin_reg.sav'\n",
    "lin_reg = pickle.load(open(filename, 'rb'))\n",
    "#print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "d4a84180",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(lin_reg)\n",
    "nomi.append(\"Linear Regressor\")\n",
    "modelli_lineari.append(\"Linear Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482761f",
   "metadata": {},
   "source": [
    "<h1>SGD Regressor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "1cacb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#sgd_reg = SGDRegressor() #maybe random_state=42\n",
    "#sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "#Salviamo il modello sul disco\n",
    "#filename = './Modelli/sgd_reg.sav'\n",
    "#pickle.dump(sgd_reg, open(filename, 'wb'))\n",
    "\n",
    "#Carichiamo il modello dal disco\n",
    "filename = './Modelli/sgd_reg.sav'\n",
    "sgd_reg = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "6223d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(sgd_reg)\n",
    "nomi.append(\"SGD Regressor\")\n",
    "modelli_lineari.append(\"SGD Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce01678",
   "metadata": {},
   "source": [
    "<h1>Ensemble Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "201a0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli_ensemble = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efed50",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "729a6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#forest_reg = RandomForestRegressor() #n_estimators=10, random_state=42\n",
    "#forest_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/forest_reg.sav'\n",
    "#pickle.dump(forest_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/forest_reg.sav'\n",
    "forest_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "bb4600b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(forest_reg)\n",
    "nomi.append(\"Forest Regressor\")\n",
    "modelli_lineari.append(\"Forest Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edf3b3",
   "metadata": {},
   "source": [
    "<h2>AdaBoost Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "935ad896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#ada_reg = AdaBoostRegressor()\n",
    "#ada_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/ada_reg.sav'\n",
    "#pickle.dump(ada_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/ada_reg.sav'\n",
    "ada_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b64807f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(ada_reg)\n",
    "nomi.append(\"Ada Regressor\")\n",
    "modelli_ensemble.append(\"Ada Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56f16e",
   "metadata": {},
   "source": [
    "<h2>Bagging Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "e9f9a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "#bagging_reg = BaggingRegressor(random_state=42)\n",
    "#bagging_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/bagging_reg.sav'\n",
    "#pickle.dump(bagging_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/bagging_reg.sav'\n",
    "bagging_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "02de0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(bagging_reg)\n",
    "nomi.append(\"Bagging Regressor\")\n",
    "modelli_ensemble.append(\"Bagging Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4942a",
   "metadata": {},
   "source": [
    "<h1>Neural networks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "d7770941",
   "metadata": {},
   "outputs": [],
   "source": [
    "reti_neurali = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "1dee8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#mlp_reg = MLPRegressor()\n",
    "#mlp_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/mlp_reg.sav'\n",
    "#pickle.dump(mlp_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/mlp_reg.sav'\n",
    "mlp_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "092a7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(mlp_reg)\n",
    "nomi.append(\"MLP Regressor\")\n",
    "reti_neurali.append(\"MLP Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3e1aa",
   "metadata": {},
   "source": [
    "<h1>Modelli ad Albero</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "d6291509",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli_alberi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b704f",
   "metadata": {},
   "source": [
    "<h2>DecisionTree Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "6a93472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "#tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/tree_reg.sav'\n",
    "#pickle.dump(tree_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/tree_reg.sav'\n",
    "tree_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "a82cabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(tree_reg)\n",
    "nomi.append(\"DecisionTree Regressor\")\n",
    "modelli_alberi.append(\"DecisionTree Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1036d1",
   "metadata": {},
   "source": [
    "<h1>Regressori basati su Istance</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "bce1d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli_istance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afc86a",
   "metadata": {},
   "source": [
    "<h2>K Neighbour Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "cd73e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#kn_reg = KNeighborsRegressor()\n",
    "#kn_reg.fit(X_train, y_train)\n",
    "\n",
    "# Salviamo il modello sul disco\n",
    "#filename = './Modelli/kn_reg.sav'\n",
    "#pickle.dump(kn_reg, open(filename, 'wb'))\n",
    "\n",
    "# Carichiamo il modello dal disco\n",
    "filename = './Modelli/kn_reg.sav'\n",
    "kn_reg = pickle.load(open(filename, 'rb'))\n",
    "# print(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "d6d27c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressori.append(kn_reg)\n",
    "nomi.append(\"K Neighbor Regressor\")\n",
    "modelli_istance.append(\"K Neighbor Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99dc9e",
   "metadata": {},
   "source": [
    "<h1>Performance modelli - Training set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "863bea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_modelli_training = compute_performance(regressori, nomi, X_train,y_train)\n",
    "#performance_train = pd.DataFrame(performance_modelli_training)\n",
    "#performance_train\n",
    "\n",
    "# Salviamo le performance ottenute su disco\n",
    "#filename = './Performance/performance_train.csv'\n",
    "#pickle.dump(performance_train, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "85e360ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carichiamo il file delle performance dal disco\n",
    "filename = './Performance/performance_train.csv'\n",
    "performance_train = pickle.load(open(filename, 'rb'))\n",
    "performance_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79719441",
   "metadata": {},
   "source": [
    "<h1>Performance modelli - Test set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "8c8f5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_modelli_training = compute_performance(regressori, nomi, X_test,y_test)\n",
    "#performance_test = pd.DataFrame(performance_modelli_training)\n",
    "#performance_test\n",
    "\n",
    "# Salviamo le performance ottenute su disco\n",
    "#filename = './Performance/performance_test.csv'\n",
    "#pickle.dump(performance_test, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "2c2a1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carichiamo il file delle performance dal disco\n",
    "filename = './Performance/performance_test.csv'\n",
    "performance_test = pickle.load(open(filename, 'rb'))\n",
    "performance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5c1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
